[ Thu Mar 20 03:06:34 2025 ] using warm up, epoch: 5
[ Thu Mar 20 03:06:38 2025 ] Parameters:
{'work_dir': 'work_dirs/first20training/ucla/baseline', 'model_saved_name': 'work_dirs/first20training/ucla/baseline\\runs', 'config': 'config/ucla/default.yaml', 'phase': 'train', 'save_score': False, 'seed': 1, 'log_interval': 100, 'save_interval': 1, 'save_epoch': 30, 'eval_interval': 5, 'print_log': True, 'show_topk': [1, 5], 'feeder': 'feeders.feeder_ucla.Feeder', 'num_worker': 8, 'train_feeder_args': {'data_path': 'joint', 'label_path': 'train', 'debug': False, 'random_choose': True, 'random_shift': False, 'random_move': False, 'window_size': 52, 'normalization': False, 'repeat': 5}, 'test_feeder_args': {'data_path': 'joint', 'label_path': 'val', 'debug': False}, 'model': 'model.baseline.Model', 'model_args': {'num_class': 10, 'num_point': 20, 'num_person': 1, 'graph': 'graph.ucla.Graph', 'graph_args': {'labeling_mode': 'spatial'}}, 'weights': None, 'ignore_weights': [], 'base_lr': 0.1, 'step': [50], 'device': [0], 'optimizer': 'SGD', 'nesterov': True, 'batch_size': 16, 'test_batch_size': 64, 'start_epoch': 0, 'num_epoch': 65, 'weight_decay': 0.0001, 'lr_decay_rate': 0.1, 'warm_up_epoch': 5}

[ Thu Mar 20 03:06:38 2025 ] # Parameters: 2073122
[ Thu Mar 20 03:06:38 2025 ] Training epoch: 1
[ Thu Mar 20 03:07:04 2025 ] 	Mean training loss: 2.7285.  Mean training acc: 21.50%.
[ Thu Mar 20 03:07:04 2025 ] 	Time consumption: [Data]43%, [Network]56%
[ Thu Mar 20 03:07:04 2025 ] Eval epoch: 1
[ Thu Mar 20 03:07:16 2025 ] 	Mean test loss of 8 batches: 2.6201707422733307.
[ Thu Mar 20 03:07:16 2025 ] 	Top1: 19.61%
[ Thu Mar 20 03:07:16 2025 ] 	Top5: 65.09%
[ Thu Mar 20 03:07:16 2025 ] Training epoch: 2
[ Thu Mar 20 03:07:38 2025 ] 	Mean training loss: 2.0799.  Mean training acc: 28.48%.
[ Thu Mar 20 03:07:38 2025 ] 	Time consumption: [Data]53%, [Network]47%
[ Thu Mar 20 03:07:38 2025 ] Eval epoch: 2
[ Thu Mar 20 03:07:49 2025 ] 	Mean test loss of 8 batches: 2.9699223041534424.
[ Thu Mar 20 03:07:49 2025 ] 	Top1: 15.73%
[ Thu Mar 20 03:07:49 2025 ] 	Top5: 68.10%
[ Thu Mar 20 03:07:49 2025 ] Training epoch: 3
[ Thu Mar 20 03:08:11 2025 ] 	Mean training loss: 1.8663.  Mean training acc: 34.43%.
[ Thu Mar 20 03:08:11 2025 ] 	Time consumption: [Data]52%, [Network]47%
[ Thu Mar 20 03:08:11 2025 ] Eval epoch: 3
[ Thu Mar 20 03:08:23 2025 ] 	Mean test loss of 8 batches: 1.9791659265756607.
[ Thu Mar 20 03:08:23 2025 ] 	Top1: 25.86%
[ Thu Mar 20 03:08:23 2025 ] 	Top5: 80.39%
[ Thu Mar 20 03:08:23 2025 ] Training epoch: 4
[ Thu Mar 20 03:08:45 2025 ] 	Mean training loss: 1.6798.  Mean training acc: 40.72%.
[ Thu Mar 20 03:08:45 2025 ] 	Time consumption: [Data]52%, [Network]48%
[ Thu Mar 20 03:08:45 2025 ] Eval epoch: 4
[ Thu Mar 20 03:08:57 2025 ] 	Mean test loss of 8 batches: 2.5066754072904587.
[ Thu Mar 20 03:08:57 2025 ] 	Top1: 23.71%
[ Thu Mar 20 03:08:57 2025 ] 	Top5: 68.10%
[ Thu Mar 20 03:08:57 2025 ] Training epoch: 5
[ Thu Mar 20 03:09:18 2025 ] 	Mean training loss: 1.5617.  Mean training acc: 43.28%.
[ Thu Mar 20 03:09:18 2025 ] 	Time consumption: [Data]52%, [Network]47%
[ Thu Mar 20 03:09:18 2025 ] Eval epoch: 5
[ Thu Mar 20 03:09:30 2025 ] 	Mean test loss of 8 batches: 2.081566706299782.
[ Thu Mar 20 03:09:30 2025 ] 	Top1: 29.53%
[ Thu Mar 20 03:09:30 2025 ] 	Top5: 75.65%
[ Thu Mar 20 03:09:30 2025 ] Training epoch: 6
[ Thu Mar 20 03:09:52 2025 ] 	Mean training loss: 1.4566.  Mean training acc: 46.68%.
[ Thu Mar 20 03:09:52 2025 ] 	Time consumption: [Data]52%, [Network]47%
[ Thu Mar 20 03:09:52 2025 ] Eval epoch: 6
[ Thu Mar 20 03:10:04 2025 ] 	Mean test loss of 8 batches: 2.0214378386735916.
[ Thu Mar 20 03:10:04 2025 ] 	Top1: 28.45%
[ Thu Mar 20 03:10:04 2025 ] 	Top5: 87.93%
[ Thu Mar 20 03:10:04 2025 ] Training epoch: 7
[ Thu Mar 20 03:10:27 2025 ] 	Mean training loss: 1.3628.  Mean training acc: 49.82%.
[ Thu Mar 20 03:10:27 2025 ] 	Time consumption: [Data]54%, [Network]45%
[ Thu Mar 20 03:10:27 2025 ] Eval epoch: 7
[ Thu Mar 20 03:10:39 2025 ] 	Mean test loss of 8 batches: 1.9446189850568771.
[ Thu Mar 20 03:10:39 2025 ] 	Top1: 35.78%
[ Thu Mar 20 03:10:39 2025 ] 	Top5: 80.60%
[ Thu Mar 20 03:10:39 2025 ] Training epoch: 8
[ Thu Mar 20 03:11:02 2025 ] 	Mean training loss: 1.3390.  Mean training acc: 50.53%.
[ Thu Mar 20 03:11:02 2025 ] 	Time consumption: [Data]53%, [Network]47%
[ Thu Mar 20 03:11:02 2025 ] Eval epoch: 8
[ Thu Mar 20 03:11:14 2025 ] 	Mean test loss of 8 batches: 1.6197461932897568.
[ Thu Mar 20 03:11:14 2025 ] 	Top1: 44.61%
[ Thu Mar 20 03:11:14 2025 ] 	Top5: 84.70%
[ Thu Mar 20 03:11:14 2025 ] Training epoch: 9
[ Thu Mar 20 03:11:35 2025 ] 	Mean training loss: 1.2900.  Mean training acc: 52.81%.
[ Thu Mar 20 03:11:35 2025 ] 	Time consumption: [Data]52%, [Network]48%
[ Thu Mar 20 03:11:35 2025 ] Eval epoch: 9
[ Thu Mar 20 03:11:47 2025 ] 	Mean test loss of 8 batches: 1.6145287901163101.
[ Thu Mar 20 03:11:47 2025 ] 	Top1: 46.12%
[ Thu Mar 20 03:11:47 2025 ] 	Top5: 84.05%
[ Thu Mar 20 03:11:47 2025 ] Training epoch: 10
[ Thu Mar 20 03:12:09 2025 ] 	Mean training loss: 1.2501.  Mean training acc: 53.79%.
[ Thu Mar 20 03:12:09 2025 ] 	Time consumption: [Data]52%, [Network]47%
[ Thu Mar 20 03:12:09 2025 ] Eval epoch: 10
[ Thu Mar 20 03:12:20 2025 ] 	Mean test loss of 8 batches: 1.7134385704994202.
[ Thu Mar 20 03:12:20 2025 ] 	Top1: 41.81%
[ Thu Mar 20 03:12:20 2025 ] 	Top5: 84.05%
[ Thu Mar 20 03:12:20 2025 ] Training epoch: 11
[ Thu Mar 20 03:12:42 2025 ] 	Mean training loss: 1.2177.  Mean training acc: 55.19%.
[ Thu Mar 20 03:12:42 2025 ] 	Time consumption: [Data]52%, [Network]48%
[ Thu Mar 20 03:12:42 2025 ] Eval epoch: 11
[ Thu Mar 20 03:12:54 2025 ] 	Mean test loss of 8 batches: 1.2768055945634842.
[ Thu Mar 20 03:12:54 2025 ] 	Top1: 56.47%
[ Thu Mar 20 03:12:54 2025 ] 	Top5: 92.46%
[ Thu Mar 20 03:12:54 2025 ] Training epoch: 12
[ Thu Mar 20 03:13:16 2025 ] 	Mean training loss: 1.1865.  Mean training acc: 56.53%.
[ Thu Mar 20 03:13:16 2025 ] 	Time consumption: [Data]51%, [Network]48%
[ Thu Mar 20 03:13:16 2025 ] Eval epoch: 12
[ Thu Mar 20 03:13:28 2025 ] 	Mean test loss of 8 batches: 2.350119262933731.
[ Thu Mar 20 03:13:28 2025 ] 	Top1: 29.31%
[ Thu Mar 20 03:13:28 2025 ] 	Top5: 75.22%
[ Thu Mar 20 03:13:28 2025 ] Training epoch: 13
[ Thu Mar 20 03:13:51 2025 ] 	Mean training loss: 1.1544.  Mean training acc: 58.00%.
[ Thu Mar 20 03:13:51 2025 ] 	Time consumption: [Data]51%, [Network]48%
[ Thu Mar 20 03:13:51 2025 ] Eval epoch: 13
[ Thu Mar 20 03:14:02 2025 ] 	Mean test loss of 8 batches: 1.342899203300476.
[ Thu Mar 20 03:14:02 2025 ] 	Top1: 50.65%
[ Thu Mar 20 03:14:02 2025 ] 	Top5: 89.87%
[ Thu Mar 20 03:14:02 2025 ] Training epoch: 14
[ Thu Mar 20 03:14:24 2025 ] 	Mean training loss: 1.1547.  Mean training acc: 57.49%.
[ Thu Mar 20 03:14:24 2025 ] 	Time consumption: [Data]52%, [Network]47%
[ Thu Mar 20 03:14:24 2025 ] Eval epoch: 14
[ Thu Mar 20 03:14:36 2025 ] 	Mean test loss of 8 batches: 1.348972663283348.
[ Thu Mar 20 03:14:36 2025 ] 	Top1: 48.28%
[ Thu Mar 20 03:14:36 2025 ] 	Top5: 96.55%
[ Thu Mar 20 03:14:36 2025 ] Training epoch: 15
[ Thu Mar 20 03:14:58 2025 ] 	Mean training loss: 1.1394.  Mean training acc: 57.53%.
[ Thu Mar 20 03:14:58 2025 ] 	Time consumption: [Data]52%, [Network]47%
[ Thu Mar 20 03:14:58 2025 ] Eval epoch: 15
[ Thu Mar 20 03:15:10 2025 ] 	Mean test loss of 8 batches: 1.2775089740753174.
[ Thu Mar 20 03:15:10 2025 ] 	Top1: 57.76%
[ Thu Mar 20 03:15:10 2025 ] 	Top5: 89.01%
[ Thu Mar 20 03:15:10 2025 ] Training epoch: 16
[ Thu Mar 20 03:15:31 2025 ] 	Mean training loss: 1.1285.  Mean training acc: 58.41%.
[ Thu Mar 20 03:15:31 2025 ] 	Time consumption: [Data]53%, [Network]47%
[ Thu Mar 20 03:15:31 2025 ] Eval epoch: 16
[ Thu Mar 20 03:15:43 2025 ] 	Mean test loss of 8 batches: 1.4301046058535576.
[ Thu Mar 20 03:15:43 2025 ] 	Top1: 49.35%
[ Thu Mar 20 03:15:43 2025 ] 	Top5: 86.85%
[ Thu Mar 20 03:15:43 2025 ] Training epoch: 17
[ Thu Mar 20 03:16:05 2025 ] 	Mean training loss: 1.0879.  Mean training acc: 60.63%.
[ Thu Mar 20 03:16:05 2025 ] 	Time consumption: [Data]53%, [Network]46%
[ Thu Mar 20 03:16:05 2025 ] Eval epoch: 17
[ Thu Mar 20 03:16:17 2025 ] 	Mean test loss of 8 batches: 1.5248695462942123.
[ Thu Mar 20 03:16:17 2025 ] 	Top1: 41.59%
[ Thu Mar 20 03:16:17 2025 ] 	Top5: 85.56%
[ Thu Mar 20 03:16:17 2025 ] Training epoch: 18
[ Thu Mar 20 03:16:38 2025 ] 	Mean training loss: 1.0822.  Mean training acc: 59.93%.
[ Thu Mar 20 03:16:38 2025 ] 	Time consumption: [Data]52%, [Network]47%
[ Thu Mar 20 03:16:38 2025 ] Eval epoch: 18
[ Thu Mar 20 03:16:50 2025 ] 	Mean test loss of 8 batches: 1.4795940965414047.
[ Thu Mar 20 03:16:50 2025 ] 	Top1: 43.32%
[ Thu Mar 20 03:16:50 2025 ] 	Top5: 92.46%
[ Thu Mar 20 03:16:50 2025 ] Training epoch: 19
[ Thu Mar 20 03:17:13 2025 ] 	Mean training loss: 1.0798.  Mean training acc: 60.48%.
[ Thu Mar 20 03:17:13 2025 ] 	Time consumption: [Data]53%, [Network]46%
[ Thu Mar 20 03:17:13 2025 ] Eval epoch: 19
[ Thu Mar 20 03:17:25 2025 ] 	Mean test loss of 8 batches: 1.432514265179634.
[ Thu Mar 20 03:17:25 2025 ] 	Top1: 50.86%
[ Thu Mar 20 03:17:25 2025 ] 	Top5: 88.79%
[ Thu Mar 20 03:17:25 2025 ] Training epoch: 20
[ Thu Mar 20 03:17:47 2025 ] 	Mean training loss: 1.0450.  Mean training acc: 62.48%.
[ Thu Mar 20 03:17:47 2025 ] 	Time consumption: [Data]53%, [Network]46%
[ Thu Mar 20 03:17:47 2025 ] Eval epoch: 20
[ Thu Mar 20 03:17:59 2025 ] 	Mean test loss of 8 batches: 1.3524110615253448.
[ Thu Mar 20 03:17:59 2025 ] 	Top1: 51.08%
[ Thu Mar 20 03:17:59 2025 ] 	Top5: 89.44%
[ Thu Mar 20 03:17:59 2025 ] Training epoch: 21
[ Thu Mar 20 03:18:22 2025 ] 	Mean training loss: 1.0499.  Mean training acc: 61.38%.
[ Thu Mar 20 03:18:22 2025 ] 	Time consumption: [Data]52%, [Network]47%
[ Thu Mar 20 03:18:22 2025 ] Eval epoch: 21
[ Thu Mar 20 03:18:34 2025 ] 	Mean test loss of 8 batches: 1.4813439697027206.
[ Thu Mar 20 03:18:34 2025 ] 	Top1: 42.67%
[ Thu Mar 20 03:18:34 2025 ] 	Top5: 90.73%
[ Thu Mar 20 03:18:34 2025 ] Training epoch: 22
[ Thu Mar 20 03:18:55 2025 ] 	Mean training loss: 1.0406.  Mean training acc: 61.62%.
[ Thu Mar 20 03:18:55 2025 ] 	Time consumption: [Data]52%, [Network]47%
[ Thu Mar 20 03:18:55 2025 ] Eval epoch: 22
[ Thu Mar 20 03:19:07 2025 ] 	Mean test loss of 8 batches: 1.2430481240153313.
[ Thu Mar 20 03:19:07 2025 ] 	Top1: 55.82%
[ Thu Mar 20 03:19:07 2025 ] 	Top5: 91.59%
[ Thu Mar 20 03:19:07 2025 ] Training epoch: 23
[ Thu Mar 20 03:19:30 2025 ] 	Mean training loss: 1.0185.  Mean training acc: 62.95%.
[ Thu Mar 20 03:19:30 2025 ] 	Time consumption: [Data]52%, [Network]47%
[ Thu Mar 20 03:19:30 2025 ] Eval epoch: 23
[ Thu Mar 20 03:19:42 2025 ] 	Mean test loss of 8 batches: 1.2250477522611618.
[ Thu Mar 20 03:19:42 2025 ] 	Top1: 52.37%
[ Thu Mar 20 03:19:42 2025 ] 	Top5: 95.69%
[ Thu Mar 20 03:19:42 2025 ] Training epoch: 24
[ Thu Mar 20 03:20:04 2025 ] 	Mean training loss: 1.0093.  Mean training acc: 62.99%.
[ Thu Mar 20 03:20:04 2025 ] 	Time consumption: [Data]52%, [Network]47%
[ Thu Mar 20 03:20:04 2025 ] Eval epoch: 24
[ Thu Mar 20 03:20:16 2025 ] 	Mean test loss of 8 batches: 1.2058138102293015.
[ Thu Mar 20 03:20:16 2025 ] 	Top1: 56.90%
[ Thu Mar 20 03:20:16 2025 ] 	Top5: 93.53%
[ Thu Mar 20 03:20:16 2025 ] Training epoch: 25
[ Thu Mar 20 03:20:38 2025 ] 	Mean training loss: 1.0081.  Mean training acc: 62.60%.
[ Thu Mar 20 03:20:38 2025 ] 	Time consumption: [Data]52%, [Network]47%
[ Thu Mar 20 03:20:38 2025 ] Eval epoch: 25
[ Thu Mar 20 03:20:50 2025 ] 	Mean test loss of 8 batches: 1.3528290465474129.
[ Thu Mar 20 03:20:50 2025 ] 	Top1: 49.57%
[ Thu Mar 20 03:20:50 2025 ] 	Top5: 92.67%
[ Thu Mar 20 03:20:50 2025 ] Training epoch: 26
[ Thu Mar 20 03:21:13 2025 ] 	Mean training loss: 0.9824.  Mean training acc: 64.41%.
[ Thu Mar 20 03:21:13 2025 ] 	Time consumption: [Data]53%, [Network]46%
[ Thu Mar 20 03:21:13 2025 ] Eval epoch: 26
[ Thu Mar 20 03:21:25 2025 ] 	Mean test loss of 8 batches: 1.1500362232327461.
[ Thu Mar 20 03:21:25 2025 ] 	Top1: 60.56%
[ Thu Mar 20 03:21:25 2025 ] 	Top5: 95.69%
[ Thu Mar 20 03:21:25 2025 ] Training epoch: 27
[ Thu Mar 20 03:21:49 2025 ] 	Mean training loss: 0.9886.  Mean training acc: 62.66%.
[ Thu Mar 20 03:21:49 2025 ] 	Time consumption: [Data]55%, [Network]44%
[ Thu Mar 20 03:21:49 2025 ] Eval epoch: 27
[ Thu Mar 20 03:22:02 2025 ] 	Mean test loss of 8 batches: 1.6107444912195206.
[ Thu Mar 20 03:22:02 2025 ] 	Top1: 48.92%
[ Thu Mar 20 03:22:02 2025 ] 	Top5: 82.33%
[ Thu Mar 20 03:22:02 2025 ] Training epoch: 28
[ Thu Mar 20 03:22:24 2025 ] 	Mean training loss: 0.9761.  Mean training acc: 64.19%.
[ Thu Mar 20 03:22:24 2025 ] 	Time consumption: [Data]52%, [Network]47%
[ Thu Mar 20 03:22:24 2025 ] Eval epoch: 28
[ Thu Mar 20 03:22:36 2025 ] 	Mean test loss of 8 batches: 1.5127599835395813.
[ Thu Mar 20 03:22:36 2025 ] 	Top1: 41.38%
[ Thu Mar 20 03:22:36 2025 ] 	Top5: 87.72%
[ Thu Mar 20 03:22:36 2025 ] Training epoch: 29
[ Thu Mar 20 03:22:57 2025 ] 	Mean training loss: 0.9450.  Mean training acc: 65.88%.
[ Thu Mar 20 03:22:57 2025 ] 	Time consumption: [Data]52%, [Network]47%
[ Thu Mar 20 03:22:57 2025 ] Eval epoch: 29
[ Thu Mar 20 03:23:09 2025 ] 	Mean test loss of 8 batches: 1.3920702934265137.
[ Thu Mar 20 03:23:09 2025 ] 	Top1: 51.08%
[ Thu Mar 20 03:23:09 2025 ] 	Top5: 88.36%
[ Thu Mar 20 03:23:09 2025 ] Training epoch: 30
[ Thu Mar 20 03:23:30 2025 ] 	Mean training loss: 0.9668.  Mean training acc: 65.19%.
[ Thu Mar 20 03:23:30 2025 ] 	Time consumption: [Data]52%, [Network]47%
[ Thu Mar 20 03:23:30 2025 ] Eval epoch: 30
[ Thu Mar 20 03:23:42 2025 ] 	Mean test loss of 8 batches: 1.4765710830688477.
[ Thu Mar 20 03:23:42 2025 ] 	Top1: 44.83%
[ Thu Mar 20 03:23:42 2025 ] 	Top5: 91.81%
[ Thu Mar 20 03:23:42 2025 ] Training epoch: 31
[ Thu Mar 20 03:24:05 2025 ] 	Mean training loss: 0.9636.  Mean training acc: 64.82%.
[ Thu Mar 20 03:24:05 2025 ] 	Time consumption: [Data]53%, [Network]46%
[ Thu Mar 20 03:24:05 2025 ] Eval epoch: 31
[ Thu Mar 20 03:24:17 2025 ] 	Mean test loss of 8 batches: 1.3812360614538193.
[ Thu Mar 20 03:24:17 2025 ] 	Top1: 46.34%
[ Thu Mar 20 03:24:17 2025 ] 	Top5: 92.03%
[ Thu Mar 20 03:24:17 2025 ] Training epoch: 32
[ Thu Mar 20 03:24:38 2025 ] 	Mean training loss: 0.9422.  Mean training acc: 66.08%.
[ Thu Mar 20 03:24:38 2025 ] 	Time consumption: [Data]52%, [Network]47%
[ Thu Mar 20 03:24:38 2025 ] Eval epoch: 32
[ Thu Mar 20 03:24:50 2025 ] 	Mean test loss of 8 batches: 1.3557043969631195.
[ Thu Mar 20 03:24:50 2025 ] 	Top1: 47.84%
[ Thu Mar 20 03:24:50 2025 ] 	Top5: 90.09%
[ Thu Mar 20 03:24:50 2025 ] Training epoch: 33
[ Thu Mar 20 03:25:12 2025 ] 	Mean training loss: 0.9557.  Mean training acc: 65.41%.
[ Thu Mar 20 03:25:12 2025 ] 	Time consumption: [Data]53%, [Network]47%
[ Thu Mar 20 03:25:12 2025 ] Eval epoch: 33
[ Thu Mar 20 03:25:24 2025 ] 	Mean test loss of 8 batches: 1.2038223147392273.
[ Thu Mar 20 03:25:24 2025 ] 	Top1: 57.76%
[ Thu Mar 20 03:25:24 2025 ] 	Top5: 92.46%
[ Thu Mar 20 03:25:24 2025 ] Training epoch: 34
[ Thu Mar 20 03:25:46 2025 ] 	Mean training loss: 0.9210.  Mean training acc: 66.45%.
[ Thu Mar 20 03:25:46 2025 ] 	Time consumption: [Data]52%, [Network]47%
[ Thu Mar 20 03:25:46 2025 ] Eval epoch: 34
[ Thu Mar 20 03:25:58 2025 ] 	Mean test loss of 8 batches: 1.369992345571518.
[ Thu Mar 20 03:25:58 2025 ] 	Top1: 57.76%
[ Thu Mar 20 03:25:58 2025 ] 	Top5: 87.07%
[ Thu Mar 20 03:25:58 2025 ] Training epoch: 35
[ Thu Mar 20 03:26:20 2025 ] 	Mean training loss: 0.9163.  Mean training acc: 66.31%.
[ Thu Mar 20 03:26:20 2025 ] 	Time consumption: [Data]52%, [Network]48%
[ Thu Mar 20 03:26:20 2025 ] Eval epoch: 35
[ Thu Mar 20 03:26:32 2025 ] 	Mean test loss of 8 batches: 1.2635599225759506.
[ Thu Mar 20 03:26:32 2025 ] 	Top1: 56.90%
[ Thu Mar 20 03:26:32 2025 ] 	Top5: 91.38%
[ Thu Mar 20 03:26:32 2025 ] Training epoch: 36
[ Thu Mar 20 03:26:54 2025 ] 	Mean training loss: 0.9163.  Mean training acc: 66.08%.
[ Thu Mar 20 03:26:54 2025 ] 	Time consumption: [Data]52%, [Network]47%
[ Thu Mar 20 03:26:54 2025 ] Eval epoch: 36
[ Thu Mar 20 03:27:05 2025 ] 	Mean test loss of 8 batches: 1.087313361465931.
[ Thu Mar 20 03:27:06 2025 ] 	Top1: 57.97%
[ Thu Mar 20 03:27:06 2025 ] 	Top5: 96.12%
[ Thu Mar 20 03:27:06 2025 ] Training epoch: 37
[ Thu Mar 20 03:27:27 2025 ] 	Mean training loss: 0.9184.  Mean training acc: 66.19%.
[ Thu Mar 20 03:27:27 2025 ] 	Time consumption: [Data]52%, [Network]48%
[ Thu Mar 20 03:27:27 2025 ] Eval epoch: 37
[ Thu Mar 20 03:27:39 2025 ] 	Mean test loss of 8 batches: 1.4741265773773193.
[ Thu Mar 20 03:27:39 2025 ] 	Top1: 45.69%
[ Thu Mar 20 03:27:39 2025 ] 	Top5: 91.38%
[ Thu Mar 20 03:27:39 2025 ] Training epoch: 38
[ Thu Mar 20 03:28:00 2025 ] 	Mean training loss: 0.8979.  Mean training acc: 67.10%.
[ Thu Mar 20 03:28:00 2025 ] 	Time consumption: [Data]52%, [Network]48%
[ Thu Mar 20 03:28:00 2025 ] Eval epoch: 38
[ Thu Mar 20 03:28:12 2025 ] 	Mean test loss of 8 batches: 1.071438767015934.
[ Thu Mar 20 03:28:12 2025 ] 	Top1: 60.99%
[ Thu Mar 20 03:28:12 2025 ] 	Top5: 98.49%
[ Thu Mar 20 03:28:12 2025 ] Training epoch: 39
[ Thu Mar 20 03:28:35 2025 ] 	Mean training loss: 0.9000.  Mean training acc: 66.41%.
[ Thu Mar 20 03:28:35 2025 ] 	Time consumption: [Data]53%, [Network]47%
[ Thu Mar 20 03:28:35 2025 ] Eval epoch: 39
[ Thu Mar 20 03:28:47 2025 ] 	Mean test loss of 8 batches: 1.2362635284662247.
[ Thu Mar 20 03:28:47 2025 ] 	Top1: 51.29%
[ Thu Mar 20 03:28:47 2025 ] 	Top5: 96.77%
[ Thu Mar 20 03:28:47 2025 ] Training epoch: 40
[ Thu Mar 20 03:29:09 2025 ] 	Mean training loss: 0.8889.  Mean training acc: 66.88%.
[ Thu Mar 20 03:29:09 2025 ] 	Time consumption: [Data]53%, [Network]47%
[ Thu Mar 20 03:29:09 2025 ] Eval epoch: 40
[ Thu Mar 20 03:29:21 2025 ] 	Mean test loss of 8 batches: 1.2473599389195442.
[ Thu Mar 20 03:29:21 2025 ] 	Top1: 50.65%
[ Thu Mar 20 03:29:21 2025 ] 	Top5: 95.04%
[ Thu Mar 20 03:29:21 2025 ] Training epoch: 41
[ Thu Mar 20 03:29:43 2025 ] 	Mean training loss: 0.8785.  Mean training acc: 67.87%.
[ Thu Mar 20 03:29:43 2025 ] 	Time consumption: [Data]53%, [Network]47%
[ Thu Mar 20 03:29:43 2025 ] Eval epoch: 41
[ Thu Mar 20 03:29:55 2025 ] 	Mean test loss of 8 batches: 1.3925439268350601.
[ Thu Mar 20 03:29:55 2025 ] 	Top1: 45.04%
[ Thu Mar 20 03:29:55 2025 ] 	Top5: 91.81%
[ Thu Mar 20 03:29:55 2025 ] Training epoch: 42
[ Thu Mar 20 03:30:17 2025 ] 	Mean training loss: 0.8683.  Mean training acc: 68.61%.
[ Thu Mar 20 03:30:17 2025 ] 	Time consumption: [Data]53%, [Network]47%
[ Thu Mar 20 03:30:17 2025 ] Eval epoch: 42
[ Thu Mar 20 03:30:28 2025 ] 	Mean test loss of 8 batches: 1.5303379446268082.
[ Thu Mar 20 03:30:28 2025 ] 	Top1: 47.84%
[ Thu Mar 20 03:30:28 2025 ] 	Top5: 83.41%
[ Thu Mar 20 03:30:28 2025 ] Training epoch: 43
[ Thu Mar 20 03:30:50 2025 ] 	Mean training loss: 0.8552.  Mean training acc: 68.18%.
[ Thu Mar 20 03:30:50 2025 ] 	Time consumption: [Data]52%, [Network]47%
[ Thu Mar 20 03:30:50 2025 ] Eval epoch: 43
[ Thu Mar 20 03:31:02 2025 ] 	Mean test loss of 8 batches: 1.4834516495466232.
[ Thu Mar 20 03:31:02 2025 ] 	Top1: 46.98%
[ Thu Mar 20 03:31:02 2025 ] 	Top5: 90.09%
[ Thu Mar 20 03:31:02 2025 ] Training epoch: 44
[ Thu Mar 20 03:31:23 2025 ] 	Mean training loss: 0.8655.  Mean training acc: 68.08%.
[ Thu Mar 20 03:31:23 2025 ] 	Time consumption: [Data]52%, [Network]48%
[ Thu Mar 20 03:31:23 2025 ] Eval epoch: 44
[ Thu Mar 20 03:31:35 2025 ] 	Mean test loss of 8 batches: 1.4277509152889252.
[ Thu Mar 20 03:31:35 2025 ] 	Top1: 59.27%
[ Thu Mar 20 03:31:35 2025 ] 	Top5: 84.70%
[ Thu Mar 20 03:31:35 2025 ] Training epoch: 45
[ Thu Mar 20 03:31:56 2025 ] 	Mean training loss: 0.8677.  Mean training acc: 68.69%.
[ Thu Mar 20 03:31:56 2025 ] 	Time consumption: [Data]52%, [Network]48%
[ Thu Mar 20 03:31:57 2025 ] Eval epoch: 45
[ Thu Mar 20 03:32:08 2025 ] 	Mean test loss of 8 batches: 1.2935454696416855.
[ Thu Mar 20 03:32:08 2025 ] 	Top1: 50.65%
[ Thu Mar 20 03:32:08 2025 ] 	Top5: 94.61%
[ Thu Mar 20 03:32:08 2025 ] Training epoch: 46
[ Thu Mar 20 03:32:30 2025 ] 	Mean training loss: 0.8285.  Mean training acc: 69.32%.
[ Thu Mar 20 03:32:30 2025 ] 	Time consumption: [Data]52%, [Network]48%
[ Thu Mar 20 03:32:30 2025 ] Eval epoch: 46
[ Thu Mar 20 03:32:41 2025 ] 	Mean test loss of 8 batches: 1.2737418413162231.
[ Thu Mar 20 03:32:41 2025 ] 	Top1: 53.66%
[ Thu Mar 20 03:32:41 2025 ] 	Top5: 93.10%
[ Thu Mar 20 03:32:41 2025 ] Training epoch: 47
[ Thu Mar 20 03:33:03 2025 ] 	Mean training loss: 0.8685.  Mean training acc: 68.32%.
[ Thu Mar 20 03:33:03 2025 ] 	Time consumption: [Data]52%, [Network]48%
[ Thu Mar 20 03:33:03 2025 ] Eval epoch: 47
[ Thu Mar 20 03:33:15 2025 ] 	Mean test loss of 8 batches: 1.4130376279354095.
[ Thu Mar 20 03:33:15 2025 ] 	Top1: 50.43%
[ Thu Mar 20 03:33:15 2025 ] 	Top5: 93.10%
[ Thu Mar 20 03:33:15 2025 ] Training epoch: 48
[ Thu Mar 20 03:33:36 2025 ] 	Mean training loss: 0.8443.  Mean training acc: 69.67%.
[ Thu Mar 20 03:33:36 2025 ] 	Time consumption: [Data]52%, [Network]47%
[ Thu Mar 20 03:33:36 2025 ] Eval epoch: 48
[ Thu Mar 20 03:33:48 2025 ] 	Mean test loss of 8 batches: 1.0907241627573967.
[ Thu Mar 20 03:33:48 2025 ] 	Top1: 65.30%
[ Thu Mar 20 03:33:48 2025 ] 	Top5: 96.55%
[ Thu Mar 20 03:33:48 2025 ] Training epoch: 49
[ Thu Mar 20 03:34:10 2025 ] 	Mean training loss: 0.8337.  Mean training acc: 69.38%.
[ Thu Mar 20 03:34:10 2025 ] 	Time consumption: [Data]53%, [Network]46%
[ Thu Mar 20 03:34:10 2025 ] Eval epoch: 49
[ Thu Mar 20 03:34:21 2025 ] 	Mean test loss of 8 batches: 1.2699754983186722.
[ Thu Mar 20 03:34:21 2025 ] 	Top1: 54.31%
[ Thu Mar 20 03:34:21 2025 ] 	Top5: 93.53%
[ Thu Mar 20 03:34:21 2025 ] Training epoch: 50
[ Thu Mar 20 03:34:43 2025 ] 	Mean training loss: 0.8254.  Mean training acc: 70.28%.
[ Thu Mar 20 03:34:43 2025 ] 	Time consumption: [Data]52%, [Network]47%
[ Thu Mar 20 03:34:43 2025 ] Eval epoch: 50
[ Thu Mar 20 03:34:54 2025 ] 	Mean test loss of 8 batches: 0.995442621409893.
[ Thu Mar 20 03:34:54 2025 ] 	Top1: 58.84%
[ Thu Mar 20 03:34:54 2025 ] 	Top5: 98.71%
[ Thu Mar 20 03:34:54 2025 ] Training epoch: 51
[ Thu Mar 20 03:35:16 2025 ] 	Mean training loss: 0.6785.  Mean training acc: 75.28%.
[ Thu Mar 20 03:35:16 2025 ] 	Time consumption: [Data]52%, [Network]48%
[ Thu Mar 20 03:35:16 2025 ] Eval epoch: 51
[ Thu Mar 20 03:35:28 2025 ] 	Mean test loss of 8 batches: 1.0685256123542786.
[ Thu Mar 20 03:35:28 2025 ] 	Top1: 60.34%
[ Thu Mar 20 03:35:28 2025 ] 	Top5: 94.83%
[ Thu Mar 20 03:35:28 2025 ] Training epoch: 52
[ Thu Mar 20 03:35:49 2025 ] 	Mean training loss: 0.6348.  Mean training acc: 75.96%.
[ Thu Mar 20 03:35:49 2025 ] 	Time consumption: [Data]52%, [Network]47%
[ Thu Mar 20 03:35:49 2025 ] Eval epoch: 52
[ Thu Mar 20 03:36:01 2025 ] 	Mean test loss of 8 batches: 1.1866121962666512.
[ Thu Mar 20 03:36:01 2025 ] 	Top1: 60.13%
[ Thu Mar 20 03:36:01 2025 ] 	Top5: 94.61%
[ Thu Mar 20 03:36:01 2025 ] Training epoch: 53
[ Thu Mar 20 03:36:22 2025 ] 	Mean training loss: 0.6134.  Mean training acc: 77.00%.
[ Thu Mar 20 03:36:22 2025 ] 	Time consumption: [Data]52%, [Network]47%
[ Thu Mar 20 03:36:22 2025 ] Eval epoch: 53
[ Thu Mar 20 03:36:35 2025 ] 	Mean test loss of 8 batches: 1.2176282331347466.
[ Thu Mar 20 03:36:35 2025 ] 	Top1: 56.47%
[ Thu Mar 20 03:36:35 2025 ] 	Top5: 94.83%
[ Thu Mar 20 03:36:35 2025 ] Training epoch: 54
[ Thu Mar 20 03:36:57 2025 ] 	Mean training loss: 0.5851.  Mean training acc: 78.38%.
[ Thu Mar 20 03:36:57 2025 ] 	Time consumption: [Data]53%, [Network]46%
[ Thu Mar 20 03:36:57 2025 ] Eval epoch: 54
[ Thu Mar 20 03:37:09 2025 ] 	Mean test loss of 8 batches: 1.1578641086816788.
[ Thu Mar 20 03:37:09 2025 ] 	Top1: 60.99%
[ Thu Mar 20 03:37:09 2025 ] 	Top5: 94.40%
[ Thu Mar 20 03:37:09 2025 ] Training epoch: 55
[ Thu Mar 20 03:37:32 2025 ] 	Mean training loss: 0.5826.  Mean training acc: 78.71%.
[ Thu Mar 20 03:37:32 2025 ] 	Time consumption: [Data]50%, [Network]49%
[ Thu Mar 20 03:37:32 2025 ] Eval epoch: 55
[ Thu Mar 20 03:37:44 2025 ] 	Mean test loss of 8 batches: 1.0787088423967361.
[ Thu Mar 20 03:37:44 2025 ] 	Top1: 63.79%
[ Thu Mar 20 03:37:44 2025 ] 	Top5: 96.55%
[ Thu Mar 20 03:37:44 2025 ] Training epoch: 56
[ Thu Mar 20 03:38:06 2025 ] 	Mean training loss: 0.5853.  Mean training acc: 78.30%.
[ Thu Mar 20 03:38:06 2025 ] 	Time consumption: [Data]52%, [Network]47%
[ Thu Mar 20 03:38:06 2025 ] Eval epoch: 56
[ Thu Mar 20 03:38:17 2025 ] 	Mean test loss of 8 batches: 1.2479076832532883.
[ Thu Mar 20 03:38:17 2025 ] 	Top1: 57.97%
[ Thu Mar 20 03:38:17 2025 ] 	Top5: 95.69%
[ Thu Mar 20 03:38:17 2025 ] Training epoch: 57
[ Thu Mar 20 03:38:39 2025 ] 	Mean training loss: 0.5531.  Mean training acc: 79.54%.
[ Thu Mar 20 03:38:39 2025 ] 	Time consumption: [Data]52%, [Network]47%
[ Thu Mar 20 03:38:39 2025 ] Eval epoch: 57
[ Thu Mar 20 03:38:51 2025 ] 	Mean test loss of 8 batches: 1.2433561235666275.
[ Thu Mar 20 03:38:51 2025 ] 	Top1: 58.19%
[ Thu Mar 20 03:38:51 2025 ] 	Top5: 95.26%
[ Thu Mar 20 03:38:51 2025 ] Training epoch: 58
[ Thu Mar 20 03:39:13 2025 ] 	Mean training loss: 0.5398.  Mean training acc: 80.13%.
[ Thu Mar 20 03:39:13 2025 ] 	Time consumption: [Data]53%, [Network]47%
[ Thu Mar 20 03:39:13 2025 ] Eval epoch: 58
[ Thu Mar 20 03:39:25 2025 ] 	Mean test loss of 8 batches: 1.2170443683862686.
[ Thu Mar 20 03:39:25 2025 ] 	Top1: 58.19%
[ Thu Mar 20 03:39:25 2025 ] 	Top5: 97.20%
[ Thu Mar 20 03:39:25 2025 ] Training epoch: 59
[ Thu Mar 20 03:39:47 2025 ] 	Mean training loss: 0.5470.  Mean training acc: 79.58%.
[ Thu Mar 20 03:39:47 2025 ] 	Time consumption: [Data]52%, [Network]47%
[ Thu Mar 20 03:39:47 2025 ] Eval epoch: 59
[ Thu Mar 20 03:39:58 2025 ] 	Mean test loss of 8 batches: 1.2907952517271042.
[ Thu Mar 20 03:39:58 2025 ] 	Top1: 56.03%
[ Thu Mar 20 03:39:58 2025 ] 	Top5: 93.10%
[ Thu Mar 20 03:39:58 2025 ] Training epoch: 60
[ Thu Mar 20 03:40:20 2025 ] 	Mean training loss: 0.5326.  Mean training acc: 81.05%.
[ Thu Mar 20 03:40:20 2025 ] 	Time consumption: [Data]52%, [Network]47%
[ Thu Mar 20 03:40:20 2025 ] Eval epoch: 60
[ Thu Mar 20 03:40:32 2025 ] 	Mean test loss of 8 batches: 1.251846194267273.
[ Thu Mar 20 03:40:32 2025 ] 	Top1: 60.34%
[ Thu Mar 20 03:40:32 2025 ] 	Top5: 95.04%
[ Thu Mar 20 03:40:32 2025 ] Training epoch: 61
[ Thu Mar 20 03:40:54 2025 ] 	Mean training loss: 0.5293.  Mean training acc: 80.15%.
[ Thu Mar 20 03:40:54 2025 ] 	Time consumption: [Data]53%, [Network]46%
[ Thu Mar 20 03:40:54 2025 ] Eval epoch: 61
[ Thu Mar 20 03:41:06 2025 ] 	Mean test loss of 8 batches: 1.2397758215665817.
[ Thu Mar 20 03:41:06 2025 ] 	Top1: 59.05%
[ Thu Mar 20 03:41:06 2025 ] 	Top5: 96.34%
[ Thu Mar 20 03:41:06 2025 ] Training epoch: 62
[ Thu Mar 20 03:41:28 2025 ] 	Mean training loss: 0.5106.  Mean training acc: 81.19%.
[ Thu Mar 20 03:41:28 2025 ] 	Time consumption: [Data]53%, [Network]47%
[ Thu Mar 20 03:41:28 2025 ] Eval epoch: 62
[ Thu Mar 20 03:41:40 2025 ] 	Mean test loss of 8 batches: 1.2694428116083145.
[ Thu Mar 20 03:41:40 2025 ] 	Top1: 57.97%
[ Thu Mar 20 03:41:40 2025 ] 	Top5: 96.12%
[ Thu Mar 20 03:41:40 2025 ] Training epoch: 63
[ Thu Mar 20 03:42:02 2025 ] 	Mean training loss: 0.4886.  Mean training acc: 82.04%.
[ Thu Mar 20 03:42:02 2025 ] 	Time consumption: [Data]52%, [Network]47%
[ Thu Mar 20 03:42:02 2025 ] Eval epoch: 63
[ Thu Mar 20 03:42:14 2025 ] 	Mean test loss of 8 batches: 1.2217068150639534.
[ Thu Mar 20 03:42:14 2025 ] 	Top1: 59.27%
[ Thu Mar 20 03:42:14 2025 ] 	Top5: 95.47%
[ Thu Mar 20 03:42:14 2025 ] Training epoch: 64
[ Thu Mar 20 03:42:36 2025 ] 	Mean training loss: 0.5066.  Mean training acc: 81.53%.
[ Thu Mar 20 03:42:36 2025 ] 	Time consumption: [Data]52%, [Network]47%
[ Thu Mar 20 03:42:36 2025 ] Eval epoch: 64
[ Thu Mar 20 03:42:47 2025 ] 	Mean test loss of 8 batches: 1.3215828239917755.
[ Thu Mar 20 03:42:47 2025 ] 	Top1: 55.39%
[ Thu Mar 20 03:42:47 2025 ] 	Top5: 96.34%
[ Thu Mar 20 03:42:47 2025 ] Training epoch: 65
[ Thu Mar 20 03:43:09 2025 ] 	Mean training loss: 0.4906.  Mean training acc: 82.47%.
[ Thu Mar 20 03:43:09 2025 ] 	Time consumption: [Data]52%, [Network]47%
[ Thu Mar 20 03:43:09 2025 ] Eval epoch: 65
[ Thu Mar 20 03:43:21 2025 ] 	Mean test loss of 8 batches: 1.3268763944506645.
[ Thu Mar 20 03:43:21 2025 ] 	Top1: 57.11%
[ Thu Mar 20 03:43:21 2025 ] 	Top5: 93.53%
[ Thu Mar 20 03:43:33 2025 ] Best accuracy: 0.6530172413793104
[ Thu Mar 20 03:43:33 2025 ] Epoch number: 48
[ Thu Mar 20 03:43:33 2025 ] Model name: work_dirs/first20training/ucla/baseline
[ Thu Mar 20 03:43:33 2025 ] Model total number of params: 2073122
[ Thu Mar 20 03:43:33 2025 ] Weight decay: 0.0001
[ Thu Mar 20 03:43:33 2025 ] Base LR: 0.1
[ Thu Mar 20 03:43:33 2025 ] Batch Size: 16
[ Thu Mar 20 03:43:33 2025 ] Test Batch Size: 64
[ Thu Mar 20 03:43:33 2025 ] seed: 1
