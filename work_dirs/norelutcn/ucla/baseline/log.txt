[ Wed Mar 19 19:29:49 2025 ] using warm up, epoch: 5
[ Wed Mar 19 19:30:00 2025 ] Parameters:
{'work_dir': 'norelutcn/ucla/baseline', 'model_saved_name': 'norelutcn/ucla/baseline\\runs', 'config': 'config/ucla/default.yaml', 'phase': 'train', 'save_score': False, 'seed': 1, 'log_interval': 100, 'save_interval': 1, 'save_epoch': 30, 'eval_interval': 5, 'print_log': True, 'show_topk': [1, 5], 'feeder': 'feeders.feeder_ucla.Feeder', 'num_worker': 8, 'train_feeder_args': {'data_path': 'joint', 'label_path': 'train', 'debug': False, 'random_choose': True, 'random_shift': False, 'random_move': False, 'window_size': 52, 'normalization': False, 'repeat': 5}, 'test_feeder_args': {'data_path': 'joint', 'label_path': 'val', 'debug': False}, 'model': 'model.baseline.Model', 'model_args': {'num_class': 10, 'num_point': 20, 'num_person': 1, 'graph': 'graph.ucla.Graph', 'graph_args': {'labeling_mode': 'spatial'}}, 'weights': None, 'ignore_weights': [], 'base_lr': 0.1, 'step': [50], 'device': [0], 'optimizer': 'SGD', 'nesterov': True, 'batch_size': 16, 'test_batch_size': 64, 'start_epoch': 0, 'num_epoch': 65, 'weight_decay': 0.0001, 'lr_decay_rate': 0.1, 'warm_up_epoch': 5}

[ Wed Mar 19 19:30:00 2025 ] # Parameters: 2073122
[ Wed Mar 19 19:30:00 2025 ] Training epoch: 1
[ Wed Mar 19 19:30:28 2025 ] 	Mean training loss: 2.1119.  Mean training acc: 36.34%.
[ Wed Mar 19 19:30:28 2025 ] 	Time consumption: [Data]41%, [Network]59%
[ Wed Mar 19 19:30:28 2025 ] Eval epoch: 1
[ Wed Mar 19 19:30:40 2025 ] 	Mean test loss of 8 batches: 1.1574094668030739.
[ Wed Mar 19 19:30:40 2025 ] 	Top1: 56.68%
[ Wed Mar 19 19:30:40 2025 ] 	Top5: 97.84%
[ Wed Mar 19 19:30:40 2025 ] Training epoch: 2
[ Wed Mar 19 19:31:04 2025 ] 	Mean training loss: 1.2872.  Mean training acc: 54.50%.
[ Wed Mar 19 19:31:04 2025 ] 	Time consumption: [Data]49%, [Network]50%
[ Wed Mar 19 19:31:04 2025 ] Eval epoch: 2
[ Wed Mar 19 19:31:16 2025 ] 	Mean test loss of 8 batches: 0.9938468560576439.
[ Wed Mar 19 19:31:16 2025 ] 	Top1: 62.93%
[ Wed Mar 19 19:31:16 2025 ] 	Top5: 97.84%
[ Wed Mar 19 19:31:16 2025 ] Training epoch: 3
[ Wed Mar 19 19:31:40 2025 ] 	Mean training loss: 1.0494.  Mean training acc: 61.93%.
[ Wed Mar 19 19:31:40 2025 ] 	Time consumption: [Data]48%, [Network]51%
[ Wed Mar 19 19:31:40 2025 ] Eval epoch: 3
[ Wed Mar 19 19:31:52 2025 ] 	Mean test loss of 8 batches: 0.8332454562187195.
[ Wed Mar 19 19:31:52 2025 ] 	Top1: 70.47%
[ Wed Mar 19 19:31:52 2025 ] 	Top5: 98.49%
[ Wed Mar 19 19:31:52 2025 ] Training epoch: 4
[ Wed Mar 19 19:32:16 2025 ] 	Mean training loss: 0.9085.  Mean training acc: 67.73%.
[ Wed Mar 19 19:32:16 2025 ] 	Time consumption: [Data]49%, [Network]50%
[ Wed Mar 19 19:32:16 2025 ] Eval epoch: 4
[ Wed Mar 19 19:32:28 2025 ] 	Mean test loss of 8 batches: 1.0940525457262993.
[ Wed Mar 19 19:32:28 2025 ] 	Top1: 61.42%
[ Wed Mar 19 19:32:28 2025 ] 	Top5: 94.40%
[ Wed Mar 19 19:32:28 2025 ] Training epoch: 5
[ Wed Mar 19 19:32:52 2025 ] 	Mean training loss: 0.8174.  Mean training acc: 69.85%.
[ Wed Mar 19 19:32:52 2025 ] 	Time consumption: [Data]49%, [Network]51%
[ Wed Mar 19 19:32:52 2025 ] Eval epoch: 5
[ Wed Mar 19 19:33:04 2025 ] 	Mean test loss of 8 batches: 1.2273752242326736.
[ Wed Mar 19 19:33:04 2025 ] 	Top1: 58.84%
[ Wed Mar 19 19:33:04 2025 ] 	Top5: 91.59%
[ Wed Mar 19 19:33:04 2025 ] Training epoch: 6
[ Wed Mar 19 19:33:27 2025 ] 	Mean training loss: 0.7375.  Mean training acc: 72.86%.
[ Wed Mar 19 19:33:27 2025 ] 	Time consumption: [Data]49%, [Network]51%
[ Wed Mar 19 19:33:27 2025 ] Eval epoch: 6
[ Wed Mar 19 19:33:39 2025 ] 	Mean test loss of 8 batches: 0.6748045980930328.
[ Wed Mar 19 19:33:39 2025 ] 	Top1: 75.65%
[ Wed Mar 19 19:33:39 2025 ] 	Top5: 98.71%
[ Wed Mar 19 19:33:39 2025 ] Training epoch: 7
[ Wed Mar 19 19:34:03 2025 ] 	Mean training loss: 0.7079.  Mean training acc: 74.23%.
[ Wed Mar 19 19:34:03 2025 ] 	Time consumption: [Data]48%, [Network]51%
[ Wed Mar 19 19:34:03 2025 ] Eval epoch: 7
[ Wed Mar 19 19:34:15 2025 ] 	Mean test loss of 8 batches: 0.6311248391866684.
[ Wed Mar 19 19:34:15 2025 ] 	Top1: 73.71%
[ Wed Mar 19 19:34:15 2025 ] 	Top5: 99.35%
[ Wed Mar 19 19:34:15 2025 ] Training epoch: 8
[ Wed Mar 19 19:34:39 2025 ] 	Mean training loss: 0.6668.  Mean training acc: 74.96%.
[ Wed Mar 19 19:34:39 2025 ] 	Time consumption: [Data]48%, [Network]51%
[ Wed Mar 19 19:34:39 2025 ] Eval epoch: 8
[ Wed Mar 19 19:34:51 2025 ] 	Mean test loss of 8 batches: 0.6059584878385067.
[ Wed Mar 19 19:34:51 2025 ] 	Top1: 75.43%
[ Wed Mar 19 19:34:51 2025 ] 	Top5: 98.92%
[ Wed Mar 19 19:34:51 2025 ] Training epoch: 9
[ Wed Mar 19 19:35:14 2025 ] 	Mean training loss: 0.6369.  Mean training acc: 76.34%.
[ Wed Mar 19 19:35:14 2025 ] 	Time consumption: [Data]48%, [Network]51%
[ Wed Mar 19 19:35:14 2025 ] Eval epoch: 9
[ Wed Mar 19 19:35:27 2025 ] 	Mean test loss of 8 batches: 0.9487744867801666.
[ Wed Mar 19 19:35:27 2025 ] 	Top1: 68.32%
[ Wed Mar 19 19:35:27 2025 ] 	Top5: 97.20%
[ Wed Mar 19 19:35:27 2025 ] Training epoch: 10
[ Wed Mar 19 19:35:51 2025 ] 	Mean training loss: 0.5669.  Mean training acc: 78.71%.
[ Wed Mar 19 19:35:51 2025 ] 	Time consumption: [Data]48%, [Network]52%
[ Wed Mar 19 19:35:51 2025 ] Eval epoch: 10
[ Wed Mar 19 19:36:03 2025 ] 	Mean test loss of 8 batches: 0.5488332249224186.
[ Wed Mar 19 19:36:03 2025 ] 	Top1: 79.74%
[ Wed Mar 19 19:36:03 2025 ] 	Top5: 99.14%
[ Wed Mar 19 19:36:03 2025 ] Training epoch: 11
[ Wed Mar 19 19:36:28 2025 ] 	Mean training loss: 0.5682.  Mean training acc: 79.07%.
[ Wed Mar 19 19:36:28 2025 ] 	Time consumption: [Data]49%, [Network]51%
[ Wed Mar 19 19:36:28 2025 ] Eval epoch: 11
[ Wed Mar 19 19:36:40 2025 ] 	Mean test loss of 8 batches: 0.5400832630693913.
[ Wed Mar 19 19:36:40 2025 ] 	Top1: 82.54%
[ Wed Mar 19 19:36:40 2025 ] 	Top5: 98.49%
[ Wed Mar 19 19:36:40 2025 ] Training epoch: 12
[ Wed Mar 19 19:37:04 2025 ] 	Mean training loss: 0.5456.  Mean training acc: 79.83%.
[ Wed Mar 19 19:37:04 2025 ] 	Time consumption: [Data]49%, [Network]50%
[ Wed Mar 19 19:37:04 2025 ] Eval epoch: 12
[ Wed Mar 19 19:37:16 2025 ] 	Mean test loss of 8 batches: 0.5205720216035843.
[ Wed Mar 19 19:37:16 2025 ] 	Top1: 79.96%
[ Wed Mar 19 19:37:16 2025 ] 	Top5: 99.57%
[ Wed Mar 19 19:37:16 2025 ] Training epoch: 13
[ Wed Mar 19 19:37:40 2025 ] 	Mean training loss: 0.5151.  Mean training acc: 80.74%.
[ Wed Mar 19 19:37:40 2025 ] 	Time consumption: [Data]49%, [Network]51%
[ Wed Mar 19 19:37:40 2025 ] Eval epoch: 13
[ Wed Mar 19 19:37:52 2025 ] 	Mean test loss of 8 batches: 0.45133623480796814.
[ Wed Mar 19 19:37:52 2025 ] 	Top1: 82.54%
[ Wed Mar 19 19:37:52 2025 ] 	Top5: 99.35%
[ Wed Mar 19 19:37:52 2025 ] Training epoch: 14
[ Wed Mar 19 19:38:16 2025 ] 	Mean training loss: 0.5234.  Mean training acc: 80.54%.
[ Wed Mar 19 19:38:16 2025 ] 	Time consumption: [Data]48%, [Network]51%
[ Wed Mar 19 19:38:16 2025 ] Eval epoch: 14
[ Wed Mar 19 19:38:28 2025 ] 	Mean test loss of 8 batches: 0.6805243492126465.
[ Wed Mar 19 19:38:28 2025 ] 	Top1: 72.63%
[ Wed Mar 19 19:38:28 2025 ] 	Top5: 99.14%
[ Wed Mar 19 19:38:28 2025 ] Training epoch: 15
[ Wed Mar 19 19:38:52 2025 ] 	Mean training loss: 0.4886.  Mean training acc: 82.13%.
[ Wed Mar 19 19:38:52 2025 ] 	Time consumption: [Data]48%, [Network]51%
[ Wed Mar 19 19:38:52 2025 ] Eval epoch: 15
[ Wed Mar 19 19:39:04 2025 ] 	Mean test loss of 8 batches: 0.4502605088055134.
[ Wed Mar 19 19:39:04 2025 ] 	Top1: 83.84%
[ Wed Mar 19 19:39:04 2025 ] 	Top5: 99.14%
[ Wed Mar 19 19:39:04 2025 ] Training epoch: 16
[ Wed Mar 19 19:39:28 2025 ] 	Mean training loss: 0.4576.  Mean training acc: 83.77%.
[ Wed Mar 19 19:39:28 2025 ] 	Time consumption: [Data]48%, [Network]51%
[ Wed Mar 19 19:39:28 2025 ] Eval epoch: 16
[ Wed Mar 19 19:39:40 2025 ] 	Mean test loss of 8 batches: 0.42800454050302505.
[ Wed Mar 19 19:39:40 2025 ] 	Top1: 81.90%
[ Wed Mar 19 19:39:40 2025 ] 	Top5: 99.35%
[ Wed Mar 19 19:39:40 2025 ] Training epoch: 17
[ Wed Mar 19 19:40:04 2025 ] 	Mean training loss: 0.4482.  Mean training acc: 83.47%.
[ Wed Mar 19 19:40:04 2025 ] 	Time consumption: [Data]49%, [Network]51%
[ Wed Mar 19 19:40:04 2025 ] Eval epoch: 17
[ Wed Mar 19 19:40:16 2025 ] 	Mean test loss of 8 batches: 0.5083339028060436.
[ Wed Mar 19 19:40:16 2025 ] 	Top1: 80.82%
[ Wed Mar 19 19:40:16 2025 ] 	Top5: 99.35%
[ Wed Mar 19 19:40:16 2025 ] Training epoch: 18
[ Wed Mar 19 19:40:40 2025 ] 	Mean training loss: 0.4427.  Mean training acc: 83.77%.
[ Wed Mar 19 19:40:40 2025 ] 	Time consumption: [Data]48%, [Network]51%
[ Wed Mar 19 19:40:40 2025 ] Eval epoch: 18
[ Wed Mar 19 19:40:52 2025 ] 	Mean test loss of 8 batches: 0.5060396380722523.
[ Wed Mar 19 19:40:52 2025 ] 	Top1: 80.39%
[ Wed Mar 19 19:40:52 2025 ] 	Top5: 99.14%
[ Wed Mar 19 19:40:52 2025 ] Training epoch: 19
[ Wed Mar 19 19:41:16 2025 ] 	Mean training loss: 0.4065.  Mean training acc: 84.96%.
[ Wed Mar 19 19:41:16 2025 ] 	Time consumption: [Data]49%, [Network]50%
[ Wed Mar 19 19:41:16 2025 ] Eval epoch: 19
[ Wed Mar 19 19:41:28 2025 ] 	Mean test loss of 8 batches: 0.47940318658947945.
[ Wed Mar 19 19:41:28 2025 ] 	Top1: 82.76%
[ Wed Mar 19 19:41:28 2025 ] 	Top5: 99.14%
[ Wed Mar 19 19:41:28 2025 ] Training epoch: 20
[ Wed Mar 19 19:41:52 2025 ] 	Mean training loss: 0.3885.  Mean training acc: 85.79%.
[ Wed Mar 19 19:41:52 2025 ] 	Time consumption: [Data]48%, [Network]52%
[ Wed Mar 19 19:41:52 2025 ] Eval epoch: 20
[ Wed Mar 19 19:42:04 2025 ] 	Mean test loss of 8 batches: 0.5525121986865997.
[ Wed Mar 19 19:42:04 2025 ] 	Top1: 80.17%
[ Wed Mar 19 19:42:04 2025 ] 	Top5: 99.35%
[ Wed Mar 19 19:42:04 2025 ] Training epoch: 21
[ Wed Mar 19 19:42:28 2025 ] 	Mean training loss: 0.3921.  Mean training acc: 85.93%.
[ Wed Mar 19 19:42:28 2025 ] 	Time consumption: [Data]49%, [Network]51%
[ Wed Mar 19 19:42:28 2025 ] Eval epoch: 21
[ Wed Mar 19 19:42:41 2025 ] 	Mean test loss of 8 batches: 0.37023721262812614.
[ Wed Mar 19 19:42:41 2025 ] 	Top1: 87.07%
[ Wed Mar 19 19:42:41 2025 ] 	Top5: 99.57%
[ Wed Mar 19 19:42:41 2025 ] Training epoch: 22
[ Wed Mar 19 19:43:05 2025 ] 	Mean training loss: 0.3684.  Mean training acc: 86.58%.
[ Wed Mar 19 19:43:05 2025 ] 	Time consumption: [Data]48%, [Network]51%
[ Wed Mar 19 19:43:05 2025 ] Eval epoch: 22
[ Wed Mar 19 19:43:17 2025 ] 	Mean test loss of 8 batches: 0.4404298420995474.
[ Wed Mar 19 19:43:17 2025 ] 	Top1: 83.62%
[ Wed Mar 19 19:43:17 2025 ] 	Top5: 99.35%
[ Wed Mar 19 19:43:17 2025 ] Training epoch: 23
[ Wed Mar 19 19:43:41 2025 ] 	Mean training loss: 0.3611.  Mean training acc: 86.64%.
[ Wed Mar 19 19:43:41 2025 ] 	Time consumption: [Data]49%, [Network]51%
[ Wed Mar 19 19:43:41 2025 ] Eval epoch: 23
[ Wed Mar 19 19:43:53 2025 ] 	Mean test loss of 8 batches: 0.3432127684354782.
[ Wed Mar 19 19:43:53 2025 ] 	Top1: 90.30%
[ Wed Mar 19 19:43:53 2025 ] 	Top5: 99.35%
[ Wed Mar 19 19:43:53 2025 ] Training epoch: 24
[ Wed Mar 19 19:44:16 2025 ] 	Mean training loss: 0.3356.  Mean training acc: 87.76%.
[ Wed Mar 19 19:44:16 2025 ] 	Time consumption: [Data]48%, [Network]51%
[ Wed Mar 19 19:44:16 2025 ] Eval epoch: 24
[ Wed Mar 19 19:44:28 2025 ] 	Mean test loss of 8 batches: 0.6183517388999462.
[ Wed Mar 19 19:44:28 2025 ] 	Top1: 76.94%
[ Wed Mar 19 19:44:28 2025 ] 	Top5: 99.14%
[ Wed Mar 19 19:44:28 2025 ] Training epoch: 25
[ Wed Mar 19 19:44:52 2025 ] 	Mean training loss: 0.3399.  Mean training acc: 87.81%.
[ Wed Mar 19 19:44:52 2025 ] 	Time consumption: [Data]48%, [Network]51%
[ Wed Mar 19 19:44:52 2025 ] Eval epoch: 25
[ Wed Mar 19 19:45:04 2025 ] 	Mean test loss of 8 batches: 0.40859075263142586.
[ Wed Mar 19 19:45:04 2025 ] 	Top1: 85.56%
[ Wed Mar 19 19:45:04 2025 ] 	Top5: 99.35%
[ Wed Mar 19 19:45:04 2025 ] Training epoch: 26
[ Wed Mar 19 19:45:28 2025 ] 	Mean training loss: 0.3171.  Mean training acc: 88.58%.
[ Wed Mar 19 19:45:28 2025 ] 	Time consumption: [Data]48%, [Network]51%
[ Wed Mar 19 19:45:28 2025 ] Eval epoch: 26
[ Wed Mar 19 19:45:40 2025 ] 	Mean test loss of 8 batches: 0.5055411383509636.
[ Wed Mar 19 19:45:40 2025 ] 	Top1: 84.91%
[ Wed Mar 19 19:45:40 2025 ] 	Top5: 98.71%
[ Wed Mar 19 19:45:40 2025 ] Training epoch: 27
[ Wed Mar 19 19:46:03 2025 ] 	Mean training loss: 0.2974.  Mean training acc: 88.99%.
[ Wed Mar 19 19:46:03 2025 ] 	Time consumption: [Data]49%, [Network]51%
[ Wed Mar 19 19:46:03 2025 ] Eval epoch: 27
[ Wed Mar 19 19:46:15 2025 ] 	Mean test loss of 8 batches: 0.44638615660369396.
[ Wed Mar 19 19:46:15 2025 ] 	Top1: 85.13%
[ Wed Mar 19 19:46:15 2025 ] 	Top5: 99.35%
[ Wed Mar 19 19:46:15 2025 ] Training epoch: 28
[ Wed Mar 19 19:46:39 2025 ] 	Mean training loss: 0.2988.  Mean training acc: 88.82%.
[ Wed Mar 19 19:46:39 2025 ] 	Time consumption: [Data]49%, [Network]51%
[ Wed Mar 19 19:46:39 2025 ] Eval epoch: 28
[ Wed Mar 19 19:46:51 2025 ] 	Mean test loss of 8 batches: 0.31023235991597176.
[ Wed Mar 19 19:46:51 2025 ] 	Top1: 88.36%
[ Wed Mar 19 19:46:51 2025 ] 	Top5: 99.57%
[ Wed Mar 19 19:46:51 2025 ] Training epoch: 29
[ Wed Mar 19 19:47:14 2025 ] 	Mean training loss: 0.2780.  Mean training acc: 89.35%.
[ Wed Mar 19 19:47:14 2025 ] 	Time consumption: [Data]49%, [Network]51%
[ Wed Mar 19 19:47:14 2025 ] Eval epoch: 29
[ Wed Mar 19 19:47:26 2025 ] 	Mean test loss of 8 batches: 0.35818968527019024.
[ Wed Mar 19 19:47:26 2025 ] 	Top1: 87.72%
[ Wed Mar 19 19:47:26 2025 ] 	Top5: 99.14%
[ Wed Mar 19 19:47:26 2025 ] Training epoch: 30
[ Wed Mar 19 19:47:50 2025 ] 	Mean training loss: 0.2703.  Mean training acc: 90.23%.
[ Wed Mar 19 19:47:50 2025 ] 	Time consumption: [Data]49%, [Network]50%
[ Wed Mar 19 19:47:50 2025 ] Eval epoch: 30
[ Wed Mar 19 19:48:03 2025 ] 	Mean test loss of 8 batches: 0.33784857764840126.
[ Wed Mar 19 19:48:03 2025 ] 	Top1: 87.50%
[ Wed Mar 19 19:48:03 2025 ] 	Top5: 99.57%
[ Wed Mar 19 19:48:03 2025 ] Training epoch: 31
[ Wed Mar 19 19:48:26 2025 ] 	Mean training loss: 0.2707.  Mean training acc: 90.00%.
[ Wed Mar 19 19:48:26 2025 ] 	Time consumption: [Data]48%, [Network]51%
[ Wed Mar 19 19:48:26 2025 ] Eval epoch: 31
[ Wed Mar 19 19:48:38 2025 ] 	Mean test loss of 8 batches: 0.469163004308939.
[ Wed Mar 19 19:48:38 2025 ] 	Top1: 84.27%
[ Wed Mar 19 19:48:38 2025 ] 	Top5: 99.35%
[ Wed Mar 19 19:48:38 2025 ] Training epoch: 32
[ Wed Mar 19 19:49:03 2025 ] 	Mean training loss: 0.2556.  Mean training acc: 91.19%.
[ Wed Mar 19 19:49:03 2025 ] 	Time consumption: [Data]49%, [Network]50%
[ Wed Mar 19 19:49:03 2025 ] Eval epoch: 32
[ Wed Mar 19 19:49:15 2025 ] 	Mean test loss of 8 batches: 0.26596642658114433.
[ Wed Mar 19 19:49:15 2025 ] 	Top1: 91.59%
[ Wed Mar 19 19:49:15 2025 ] 	Top5: 99.35%
[ Wed Mar 19 19:49:15 2025 ] Training epoch: 33
[ Wed Mar 19 19:49:39 2025 ] 	Mean training loss: 0.2588.  Mean training acc: 90.72%.
[ Wed Mar 19 19:49:39 2025 ] 	Time consumption: [Data]48%, [Network]51%
[ Wed Mar 19 19:49:39 2025 ] Eval epoch: 33
[ Wed Mar 19 19:49:51 2025 ] 	Mean test loss of 8 batches: 0.31099022179841995.
[ Wed Mar 19 19:49:51 2025 ] 	Top1: 89.66%
[ Wed Mar 19 19:49:51 2025 ] 	Top5: 99.14%
[ Wed Mar 19 19:49:51 2025 ] Training epoch: 34
[ Wed Mar 19 19:50:15 2025 ] 	Mean training loss: 0.2251.  Mean training acc: 92.00%.
[ Wed Mar 19 19:50:15 2025 ] 	Time consumption: [Data]48%, [Network]51%
[ Wed Mar 19 19:50:15 2025 ] Eval epoch: 34
[ Wed Mar 19 19:50:27 2025 ] 	Mean test loss of 8 batches: 0.29711563140153885.
[ Wed Mar 19 19:50:27 2025 ] 	Top1: 88.79%
[ Wed Mar 19 19:50:27 2025 ] 	Top5: 99.78%
[ Wed Mar 19 19:50:27 2025 ] Training epoch: 35
[ Wed Mar 19 19:50:50 2025 ] 	Mean training loss: 0.2238.  Mean training acc: 92.02%.
[ Wed Mar 19 19:50:50 2025 ] 	Time consumption: [Data]48%, [Network]52%
[ Wed Mar 19 19:50:50 2025 ] Eval epoch: 35
[ Wed Mar 19 19:51:02 2025 ] 	Mean test loss of 8 batches: 0.255985863506794.
[ Wed Mar 19 19:51:02 2025 ] 	Top1: 92.46%
[ Wed Mar 19 19:51:02 2025 ] 	Top5: 99.35%
[ Wed Mar 19 19:51:02 2025 ] Training epoch: 36
[ Wed Mar 19 19:51:25 2025 ] 	Mean training loss: 0.2334.  Mean training acc: 91.57%.
[ Wed Mar 19 19:51:25 2025 ] 	Time consumption: [Data]48%, [Network]51%
[ Wed Mar 19 19:51:25 2025 ] Eval epoch: 36
[ Wed Mar 19 19:51:37 2025 ] 	Mean test loss of 8 batches: 0.39049934409558773.
[ Wed Mar 19 19:51:37 2025 ] 	Top1: 86.21%
[ Wed Mar 19 19:51:37 2025 ] 	Top5: 99.57%
[ Wed Mar 19 19:51:37 2025 ] Training epoch: 37
[ Wed Mar 19 19:52:01 2025 ] 	Mean training loss: 0.2073.  Mean training acc: 92.18%.
[ Wed Mar 19 19:52:01 2025 ] 	Time consumption: [Data]48%, [Network]52%
[ Wed Mar 19 19:52:01 2025 ] Eval epoch: 37
[ Wed Mar 19 19:52:13 2025 ] 	Mean test loss of 8 batches: 0.36035607755184174.
[ Wed Mar 19 19:52:13 2025 ] 	Top1: 88.79%
[ Wed Mar 19 19:52:13 2025 ] 	Top5: 99.35%
[ Wed Mar 19 19:52:13 2025 ] Training epoch: 38
[ Wed Mar 19 19:52:36 2025 ] 	Mean training loss: 0.1920.  Mean training acc: 93.08%.
[ Wed Mar 19 19:52:36 2025 ] 	Time consumption: [Data]48%, [Network]51%
[ Wed Mar 19 19:52:36 2025 ] Eval epoch: 38
[ Wed Mar 19 19:52:48 2025 ] 	Mean test loss of 8 batches: 0.3209255994297564.
[ Wed Mar 19 19:52:48 2025 ] 	Top1: 87.93%
[ Wed Mar 19 19:52:48 2025 ] 	Top5: 99.14%
[ Wed Mar 19 19:52:48 2025 ] Training epoch: 39
[ Wed Mar 19 19:53:12 2025 ] 	Mean training loss: 0.1857.  Mean training acc: 93.46%.
[ Wed Mar 19 19:53:12 2025 ] 	Time consumption: [Data]48%, [Network]51%
[ Wed Mar 19 19:53:12 2025 ] Eval epoch: 39
[ Wed Mar 19 19:53:23 2025 ] 	Mean test loss of 8 batches: 0.36256164871156216.
[ Wed Mar 19 19:53:23 2025 ] 	Top1: 87.07%
[ Wed Mar 19 19:53:23 2025 ] 	Top5: 99.35%
[ Wed Mar 19 19:53:23 2025 ] Training epoch: 40
[ Wed Mar 19 19:53:47 2025 ] 	Mean training loss: 0.2079.  Mean training acc: 92.67%.
[ Wed Mar 19 19:53:47 2025 ] 	Time consumption: [Data]48%, [Network]51%
[ Wed Mar 19 19:53:47 2025 ] Eval epoch: 40
[ Wed Mar 19 19:53:59 2025 ] 	Mean test loss of 8 batches: 0.36741397716104984.
[ Wed Mar 19 19:53:59 2025 ] 	Top1: 86.42%
[ Wed Mar 19 19:53:59 2025 ] 	Top5: 99.57%
[ Wed Mar 19 19:53:59 2025 ] Training epoch: 41
[ Wed Mar 19 19:54:22 2025 ] 	Mean training loss: 0.1884.  Mean training acc: 93.32%.
[ Wed Mar 19 19:54:22 2025 ] 	Time consumption: [Data]48%, [Network]52%
[ Wed Mar 19 19:54:23 2025 ] Eval epoch: 41
[ Wed Mar 19 19:54:34 2025 ] 	Mean test loss of 8 batches: 0.28994443267583847.
[ Wed Mar 19 19:54:34 2025 ] 	Top1: 90.52%
[ Wed Mar 19 19:54:34 2025 ] 	Top5: 99.57%
[ Wed Mar 19 19:54:34 2025 ] Training epoch: 42
[ Wed Mar 19 19:54:58 2025 ] 	Mean training loss: 0.1857.  Mean training acc: 93.51%.
[ Wed Mar 19 19:54:58 2025 ] 	Time consumption: [Data]49%, [Network]51%
[ Wed Mar 19 19:54:58 2025 ] Eval epoch: 42
[ Wed Mar 19 19:55:10 2025 ] 	Mean test loss of 8 batches: 0.28710829745978117.
[ Wed Mar 19 19:55:10 2025 ] 	Top1: 92.03%
[ Wed Mar 19 19:55:10 2025 ] 	Top5: 99.35%
[ Wed Mar 19 19:55:10 2025 ] Training epoch: 43
[ Wed Mar 19 19:55:33 2025 ] 	Mean training loss: 0.1785.  Mean training acc: 93.83%.
[ Wed Mar 19 19:55:33 2025 ] 	Time consumption: [Data]48%, [Network]51%
[ Wed Mar 19 19:55:33 2025 ] Eval epoch: 43
[ Wed Mar 19 19:55:45 2025 ] 	Mean test loss of 8 batches: 0.30299750808626413.
[ Wed Mar 19 19:55:45 2025 ] 	Top1: 90.30%
[ Wed Mar 19 19:55:45 2025 ] 	Top5: 99.35%
[ Wed Mar 19 19:55:45 2025 ] Training epoch: 44
[ Wed Mar 19 19:56:09 2025 ] 	Mean training loss: 0.1666.  Mean training acc: 94.32%.
[ Wed Mar 19 19:56:09 2025 ] 	Time consumption: [Data]48%, [Network]52%
[ Wed Mar 19 19:56:09 2025 ] Eval epoch: 44
[ Wed Mar 19 19:56:21 2025 ] 	Mean test loss of 8 batches: 0.472167307510972.
[ Wed Mar 19 19:56:21 2025 ] 	Top1: 83.19%
[ Wed Mar 19 19:56:21 2025 ] 	Top5: 98.92%
[ Wed Mar 19 19:56:21 2025 ] Training epoch: 45
[ Wed Mar 19 19:56:44 2025 ] 	Mean training loss: 0.1775.  Mean training acc: 93.51%.
[ Wed Mar 19 19:56:44 2025 ] 	Time consumption: [Data]48%, [Network]51%
[ Wed Mar 19 19:56:44 2025 ] Eval epoch: 45
[ Wed Mar 19 19:56:56 2025 ] 	Mean test loss of 8 batches: 0.38475437834858894.
[ Wed Mar 19 19:56:56 2025 ] 	Top1: 88.15%
[ Wed Mar 19 19:56:56 2025 ] 	Top5: 99.35%
[ Wed Mar 19 19:56:56 2025 ] Training epoch: 46
[ Wed Mar 19 19:57:20 2025 ] 	Mean training loss: 0.1563.  Mean training acc: 94.52%.
[ Wed Mar 19 19:57:20 2025 ] 	Time consumption: [Data]48%, [Network]51%
[ Wed Mar 19 19:57:20 2025 ] Eval epoch: 46
[ Wed Mar 19 19:57:32 2025 ] 	Mean test loss of 8 batches: 0.5295572690665722.
[ Wed Mar 19 19:57:32 2025 ] 	Top1: 83.62%
[ Wed Mar 19 19:57:32 2025 ] 	Top5: 99.14%
[ Wed Mar 19 19:57:32 2025 ] Training epoch: 47
[ Wed Mar 19 19:57:55 2025 ] 	Mean training loss: 0.1686.  Mean training acc: 94.16%.
[ Wed Mar 19 19:57:55 2025 ] 	Time consumption: [Data]48%, [Network]51%
[ Wed Mar 19 19:57:55 2025 ] Eval epoch: 47
[ Wed Mar 19 19:58:07 2025 ] 	Mean test loss of 8 batches: 0.49007630441337824.
[ Wed Mar 19 19:58:07 2025 ] 	Top1: 80.82%
[ Wed Mar 19 19:58:07 2025 ] 	Top5: 99.57%
[ Wed Mar 19 19:58:07 2025 ] Training epoch: 48
[ Wed Mar 19 19:58:31 2025 ] 	Mean training loss: 0.1575.  Mean training acc: 94.46%.
[ Wed Mar 19 19:58:31 2025 ] 	Time consumption: [Data]48%, [Network]52%
[ Wed Mar 19 19:58:31 2025 ] Eval epoch: 48
[ Wed Mar 19 19:58:43 2025 ] 	Mean test loss of 8 batches: 0.42329070158302784.
[ Wed Mar 19 19:58:43 2025 ] 	Top1: 84.70%
[ Wed Mar 19 19:58:43 2025 ] 	Top5: 99.57%
[ Wed Mar 19 19:58:43 2025 ] Training epoch: 49
[ Wed Mar 19 19:59:06 2025 ] 	Mean training loss: 0.1344.  Mean training acc: 95.32%.
[ Wed Mar 19 19:59:06 2025 ] 	Time consumption: [Data]48%, [Network]51%
[ Wed Mar 19 19:59:06 2025 ] Eval epoch: 49
[ Wed Mar 19 19:59:18 2025 ] 	Mean test loss of 8 batches: 0.3641698770225048.
[ Wed Mar 19 19:59:18 2025 ] 	Top1: 88.15%
[ Wed Mar 19 19:59:18 2025 ] 	Top5: 99.35%
[ Wed Mar 19 19:59:18 2025 ] Training epoch: 50
[ Wed Mar 19 19:59:42 2025 ] 	Mean training loss: 0.1442.  Mean training acc: 94.87%.
[ Wed Mar 19 19:59:42 2025 ] 	Time consumption: [Data]48%, [Network]52%
[ Wed Mar 19 19:59:42 2025 ] Eval epoch: 50
[ Wed Mar 19 19:59:53 2025 ] 	Mean test loss of 8 batches: 0.3781104451045394.
[ Wed Mar 19 19:59:53 2025 ] 	Top1: 88.36%
[ Wed Mar 19 19:59:53 2025 ] 	Top5: 99.14%
[ Wed Mar 19 19:59:53 2025 ] Training epoch: 51
[ Wed Mar 19 20:00:17 2025 ] 	Mean training loss: 0.0724.  Mean training acc: 97.74%.
[ Wed Mar 19 20:00:17 2025 ] 	Time consumption: [Data]48%, [Network]52%
[ Wed Mar 19 20:00:17 2025 ] Eval epoch: 51
[ Wed Mar 19 20:00:29 2025 ] 	Mean test loss of 8 batches: 0.2769527118653059.
[ Wed Mar 19 20:00:29 2025 ] 	Top1: 90.30%
[ Wed Mar 19 20:00:29 2025 ] 	Top5: 99.14%
[ Wed Mar 19 20:00:29 2025 ] Training epoch: 52
[ Wed Mar 19 20:00:53 2025 ] 	Mean training loss: 0.0466.  Mean training acc: 98.60%.
[ Wed Mar 19 20:00:53 2025 ] 	Time consumption: [Data]48%, [Network]51%
[ Wed Mar 19 20:00:53 2025 ] Eval epoch: 52
[ Wed Mar 19 20:01:04 2025 ] 	Mean test loss of 8 batches: 0.24475541152060032.
[ Wed Mar 19 20:01:04 2025 ] 	Top1: 89.87%
[ Wed Mar 19 20:01:04 2025 ] 	Top5: 99.35%
[ Wed Mar 19 20:01:04 2025 ] Training epoch: 53
[ Wed Mar 19 20:01:28 2025 ] 	Mean training loss: 0.0411.  Mean training acc: 98.74%.
[ Wed Mar 19 20:01:28 2025 ] 	Time consumption: [Data]48%, [Network]51%
[ Wed Mar 19 20:01:28 2025 ] Eval epoch: 53
[ Wed Mar 19 20:01:40 2025 ] 	Mean test loss of 8 batches: 0.25989126041531563.
[ Wed Mar 19 20:01:40 2025 ] 	Top1: 91.38%
[ Wed Mar 19 20:01:40 2025 ] 	Top5: 99.35%
[ Wed Mar 19 20:01:40 2025 ] Training epoch: 54
[ Wed Mar 19 20:02:03 2025 ] 	Mean training loss: 0.0397.  Mean training acc: 98.80%.
[ Wed Mar 19 20:02:03 2025 ] 	Time consumption: [Data]48%, [Network]52%
[ Wed Mar 19 20:02:03 2025 ] Eval epoch: 54
[ Wed Mar 19 20:02:15 2025 ] 	Mean test loss of 8 batches: 0.25814385153353214.
[ Wed Mar 19 20:02:15 2025 ] 	Top1: 90.52%
[ Wed Mar 19 20:02:15 2025 ] 	Top5: 99.35%
[ Wed Mar 19 20:02:15 2025 ] Training epoch: 55
[ Wed Mar 19 20:02:39 2025 ] 	Mean training loss: 0.0345.  Mean training acc: 99.04%.
[ Wed Mar 19 20:02:39 2025 ] 	Time consumption: [Data]48%, [Network]51%
[ Wed Mar 19 20:02:39 2025 ] Eval epoch: 55
[ Wed Mar 19 20:02:51 2025 ] 	Mean test loss of 8 batches: 0.2530301781371236.
[ Wed Mar 19 20:02:51 2025 ] 	Top1: 91.59%
[ Wed Mar 19 20:02:51 2025 ] 	Top5: 99.35%
[ Wed Mar 19 20:02:51 2025 ] Training epoch: 56
[ Wed Mar 19 20:03:14 2025 ] 	Mean training loss: 0.0294.  Mean training acc: 99.27%.
[ Wed Mar 19 20:03:14 2025 ] 	Time consumption: [Data]48%, [Network]51%
[ Wed Mar 19 20:03:14 2025 ] Eval epoch: 56
[ Wed Mar 19 20:03:26 2025 ] 	Mean test loss of 8 batches: 0.27548350766301155.
[ Wed Mar 19 20:03:26 2025 ] 	Top1: 89.22%
[ Wed Mar 19 20:03:26 2025 ] 	Top5: 99.35%
[ Wed Mar 19 20:03:26 2025 ] Training epoch: 57
[ Wed Mar 19 20:03:50 2025 ] 	Mean training loss: 0.0318.  Mean training acc: 99.06%.
[ Wed Mar 19 20:03:50 2025 ] 	Time consumption: [Data]48%, [Network]51%
[ Wed Mar 19 20:03:50 2025 ] Eval epoch: 57
[ Wed Mar 19 20:04:02 2025 ] 	Mean test loss of 8 batches: 0.332244198769331.
[ Wed Mar 19 20:04:02 2025 ] 	Top1: 88.58%
[ Wed Mar 19 20:04:02 2025 ] 	Top5: 99.35%
[ Wed Mar 19 20:04:02 2025 ] Training epoch: 58
[ Wed Mar 19 20:04:25 2025 ] 	Mean training loss: 0.0274.  Mean training acc: 99.29%.
[ Wed Mar 19 20:04:25 2025 ] 	Time consumption: [Data]48%, [Network]52%
[ Wed Mar 19 20:04:25 2025 ] Eval epoch: 58
[ Wed Mar 19 20:04:37 2025 ] 	Mean test loss of 8 batches: 0.24918496701866388.
[ Wed Mar 19 20:04:37 2025 ] 	Top1: 91.59%
[ Wed Mar 19 20:04:37 2025 ] 	Top5: 99.35%
[ Wed Mar 19 20:04:37 2025 ] Training epoch: 59
[ Wed Mar 19 20:05:00 2025 ] 	Mean training loss: 0.0230.  Mean training acc: 99.33%.
[ Wed Mar 19 20:05:00 2025 ] 	Time consumption: [Data]48%, [Network]52%
[ Wed Mar 19 20:05:00 2025 ] Eval epoch: 59
[ Wed Mar 19 20:05:12 2025 ] 	Mean test loss of 8 batches: 0.2706805281341076.
[ Wed Mar 19 20:05:12 2025 ] 	Top1: 90.09%
[ Wed Mar 19 20:05:12 2025 ] 	Top5: 99.35%
[ Wed Mar 19 20:05:12 2025 ] Training epoch: 60
[ Wed Mar 19 20:05:35 2025 ] 	Mean training loss: 0.0216.  Mean training acc: 99.43%.
[ Wed Mar 19 20:05:35 2025 ] 	Time consumption: [Data]48%, [Network]51%
[ Wed Mar 19 20:05:35 2025 ] Eval epoch: 60
[ Wed Mar 19 20:05:47 2025 ] 	Mean test loss of 8 batches: 0.30557409673929214.
[ Wed Mar 19 20:05:47 2025 ] 	Top1: 89.87%
[ Wed Mar 19 20:05:47 2025 ] 	Top5: 99.14%
[ Wed Mar 19 20:05:47 2025 ] Training epoch: 61
[ Wed Mar 19 20:06:10 2025 ] 	Mean training loss: 0.0191.  Mean training acc: 99.51%.
[ Wed Mar 19 20:06:10 2025 ] 	Time consumption: [Data]48%, [Network]52%
[ Wed Mar 19 20:06:10 2025 ] Eval epoch: 61
[ Wed Mar 19 20:06:22 2025 ] 	Mean test loss of 8 batches: 0.30026179924607277.
[ Wed Mar 19 20:06:22 2025 ] 	Top1: 89.01%
[ Wed Mar 19 20:06:22 2025 ] 	Top5: 99.35%
[ Wed Mar 19 20:06:22 2025 ] Training epoch: 62
[ Wed Mar 19 20:06:45 2025 ] 	Mean training loss: 0.0194.  Mean training acc: 99.51%.
[ Wed Mar 19 20:06:45 2025 ] 	Time consumption: [Data]48%, [Network]51%
[ Wed Mar 19 20:06:45 2025 ] Eval epoch: 62
[ Wed Mar 19 20:50:45 2025 ] 	Mean test loss of 8 batches: 0.31590257957577705.
[ Wed Mar 19 20:50:45 2025 ] 	Top1: 89.66%
[ Wed Mar 19 20:50:45 2025 ] 	Top5: 99.14%
[ Wed Mar 19 20:50:45 2025 ] Training epoch: 63
[ Wed Mar 19 20:51:09 2025 ] 	Mean training loss: 0.0173.  Mean training acc: 99.57%.
[ Wed Mar 19 20:51:09 2025 ] 	Time consumption: [Data]50%, [Network]50%
[ Wed Mar 19 20:51:09 2025 ] Eval epoch: 63
[ Wed Mar 19 20:51:21 2025 ] 	Mean test loss of 8 batches: 0.27849234361201525.
[ Wed Mar 19 20:51:21 2025 ] 	Top1: 90.73%
[ Wed Mar 19 20:51:21 2025 ] 	Top5: 99.57%
[ Wed Mar 19 20:51:21 2025 ] Training epoch: 64
[ Wed Mar 19 20:51:44 2025 ] 	Mean training loss: 0.0216.  Mean training acc: 99.33%.
[ Wed Mar 19 20:51:44 2025 ] 	Time consumption: [Data]48%, [Network]51%
[ Wed Mar 19 20:51:44 2025 ] Eval epoch: 64
[ Wed Mar 19 20:51:56 2025 ] 	Mean test loss of 8 batches: 0.31165664084255695.
[ Wed Mar 19 20:51:56 2025 ] 	Top1: 90.52%
[ Wed Mar 19 20:51:56 2025 ] 	Top5: 99.14%
[ Wed Mar 19 20:51:56 2025 ] Training epoch: 65
[ Wed Mar 19 20:52:20 2025 ] 	Mean training loss: 0.0208.  Mean training acc: 99.43%.
[ Wed Mar 19 20:52:20 2025 ] 	Time consumption: [Data]48%, [Network]51%
[ Wed Mar 19 20:52:20 2025 ] Eval epoch: 65
[ Wed Mar 19 20:52:32 2025 ] 	Mean test loss of 8 batches: 0.2855793498456478.
[ Wed Mar 19 20:52:32 2025 ] 	Top1: 89.87%
[ Wed Mar 19 20:52:32 2025 ] 	Top5: 99.35%
[ Wed Mar 19 20:52:44 2025 ] Best accuracy: 0.9245689655172413
[ Wed Mar 19 20:52:44 2025 ] Epoch number: 35
[ Wed Mar 19 20:52:44 2025 ] Model name: norelutcn/ucla/baseline
[ Wed Mar 19 20:52:44 2025 ] Model total number of params: 2073122
[ Wed Mar 19 20:52:44 2025 ] Weight decay: 0.0001
[ Wed Mar 19 20:52:44 2025 ] Base LR: 0.1
[ Wed Mar 19 20:52:44 2025 ] Batch Size: 16
[ Wed Mar 19 20:52:44 2025 ] Test Batch Size: 64
[ Wed Mar 19 20:52:44 2025 ] seed: 1
